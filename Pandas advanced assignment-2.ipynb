{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdf32dd",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866263e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "1  Machine Learning         3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "df.iloc[1:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c50ba0",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57827c83",
   "metadata": {},
   "source": [
    "In a Pandas DataFrame, both loc and iloc are used for indexing and selecting data, but they have some key differences in terms of how they specify and interpret the indices.\n",
    "\n",
    "\n",
    "1. 'loc' (label-based indexing):\n",
    "loc is primarily label-based indexing, which means that you use the actual row and column labels to index into the DataFrame. It is inclusive of both the start and stop indices, similar to slicing in Python. The syntax is df.loc[row_indexer, column_indexer], where row_indexer and column_indexer can be labels or boolean arrays.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2. 'iloc' (integer based indexing):\n",
    "iloc is integer-location based indexing, which means that you use integer indices to index into the DataFrame. It is exclusive of the stop index, similar to Python standard slicing. The syntax is df.iloc[row_indexer, column_indexer], where row_indexer and column_indexer are integer indices or boolean arrays.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682b05f",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b101b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc result :\n",
      "  course_name    Big Data\n",
      "duration              6\n",
      "Name: 2, dtype: object\n",
      "\n",
      "iloc result :\n",
      "  course_name    Machine Learning\n",
      "duration                      3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "reindex_order = [3,0,1,2]\n",
    "new_df=df.reindex(reindex_order)\n",
    "print(\"loc result :\\n \",new_df.loc[2])\n",
    "\n",
    "print(\"\\niloc result :\\n \",new_df.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9603f",
   "metadata": {},
   "source": [
    "The loc function is inclusive of the higher limit therefore it gives the row values that are present at the second index. The iloc on the other hand is'nt inclusive of the higher limit and gives us the data present in the row before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60030a",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16d740e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of column_1 is 0.38792596376102334\n",
      "mean of column_2 is 0.6164745629238838\n",
      "mean of column_3 is 0.5480323834904904\n",
      "mean of column_4 is 0.5211863299140584\n",
      "mean of column_5 is 0.5278076323469649\n",
      "mean of column_6 is 0.46213797014225316\n",
      "\n",
      " standard deviation of column 2 is : 0.321817259972617\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "\n",
    "for column in df1.columns:\n",
    "    print(f\"mean of {column} is {df1[column].mean()}\")\n",
    "    \n",
    "print(\"\\n standard deviation of column 2 is :\",df1['column_2'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66083847",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31da444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_1</th>\n",
       "      <th>column_2</th>\n",
       "      <th>column_3</th>\n",
       "      <th>column_4</th>\n",
       "      <th>column_5</th>\n",
       "      <th>column_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.356604</td>\n",
       "      <td>0.567219</td>\n",
       "      <td>0.639221</td>\n",
       "      <td>0.867860</td>\n",
       "      <td>0.690918</td>\n",
       "      <td>0.052902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.924803</td>\n",
       "      <td>Replacement</td>\n",
       "      <td>0.714596</td>\n",
       "      <td>0.414128</td>\n",
       "      <td>0.847265</td>\n",
       "      <td>0.485718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233201</td>\n",
       "      <td>0.161226</td>\n",
       "      <td>0.243226</td>\n",
       "      <td>0.179968</td>\n",
       "      <td>0.661614</td>\n",
       "      <td>0.273929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087101</td>\n",
       "      <td>0.884417</td>\n",
       "      <td>0.716739</td>\n",
       "      <td>0.265468</td>\n",
       "      <td>0.786393</td>\n",
       "      <td>0.808766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.564596</td>\n",
       "      <td>0.842072</td>\n",
       "      <td>0.622872</td>\n",
       "      <td>0.427528</td>\n",
       "      <td>0.120392</td>\n",
       "      <td>0.929520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   column_1     column_2  column_3  column_4  column_5  column_6\n",
       "1  0.356604     0.567219  0.639221  0.867860  0.690918  0.052902\n",
       "2  0.924803  Replacement  0.714596  0.414128  0.847265  0.485718\n",
       "3  0.233201     0.161226  0.243226  0.179968  0.661614  0.273929\n",
       "4  0.087101     0.884417  0.716739  0.265468  0.786393  0.808766\n",
       "5  0.564596     0.842072  0.622872  0.427528  0.120392  0.929520"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## replacing data present in the 2nd column \n",
    "replacement_string='Replacement'\n",
    "df1.loc[2,'column_2']=replacement_string\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec1db5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m  11830\u001b[0m     _num_doc,\n\u001b[0;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11846\u001b[0m ):\n\u001b[1;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, level, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11403\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m  11349\u001b[0m     )\n\u001b[0;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[0;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11352\u001b[0m     )\n\u001b[1;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11354\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11355\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4814\u001b[0m     )\n\u001b[0;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[0;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum))\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "print(df1['column_2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97966c86",
   "metadata": {},
   "source": [
    "we encounter this error because the data point present in the row is not a float or integer value and therefore the mean cannot be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300ba9a",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be937332",
   "metadata": {},
   "source": [
    "In Pandas, window functions are operations that perform calculations on a specified subset of data defined by a window of consecutive rows. These functions are particularly useful for time series data and can be applied to rolling or expanding windows. The core idea is to perform aggregate or transformation operations over a moving window of data. These functions operate on a fixed-size window of data that \"rolls\" along the time series.\n",
    "Common rolling window functions include:\n",
    "1. rolling().mean() : calculates rolling mean\n",
    "2. rolling().sum() : Calculates rolling sum\n",
    "3. rolling().min() and rolling().max() : Calculates the rolling minimum and maximum\n",
    "4. rolling().std() : Calculates the rolling standard deviation\n",
    "5. rolling().apply() : Applies a custom function to the rolling window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdcbf4",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5592b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month is 12 and current year is 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_11636\\3906659472.py:2: FutureWarning: The parsing of 'now' in pd.to_datetime without `utc=True` is deprecated. In a future version, this will match Timestamp('now') and Timestamp.now()\n",
      "  current_datetime=pd.to_datetime('now')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "current_datetime=pd.to_datetime('now')\n",
    "current_month=current_datetime.month\n",
    "current_year=current_datetime.year\n",
    "\n",
    "print(f\"Current Month is {current_month} and current year is {current_year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5570fed",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75211c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter start date in YYYY-MM-DD format2023-05-17\n",
      "enter end date in YYYY-MM-DD format2023-12-12\n",
      "\n",
      "Time Difference:\n",
      "Days: 209 days\n",
      "Hours: 0 hours\n",
      "Minutes: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "start_date=pd.to_datetime(input(\"enter start date in YYYY-MM-DD format\"))\n",
    "end_date=pd.to_datetime(input(\"enter end date in YYYY-MM-DD format\"))\n",
    "time_diff=end_date-start_date\n",
    "days=time_diff.days\n",
    "hours,remainder=divmod(time_diff.seconds,3600)\n",
    "minutes,_=divmod(remainder,60)\n",
    "print(f\"\\nTime Difference:\")\n",
    "print(f\"Days: {days} days\")\n",
    "print(f\"Hours: {hours} hours\")\n",
    "print(f\"Minutes: {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942af782",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffe0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def main():\n",
    "    \n",
    "    file_path=input(\"Enter the path of your csv file\")\n",
    "    df=pd.read_csv(file_path)\n",
    "    column_name=input(\"\\nEnter the column to be converted to categorical type\")\n",
    "    if column_name not in df.columns:\n",
    "        print(\"Error the column entered not found in DataFrame\")\n",
    "        return\n",
    "    \n",
    "\n",
    "    cateory_order=input(\"\\nEnter the category order (comma seperated)\")\n",
    "    category_order=[cat.strip() for cat in cateory_order.split(',')]\n",
    "\n",
    "    convert_to_categorical(df,column_name,category_order)\n",
    "    sorted_df=df.sort_values(by=[column_name])\n",
    "    print(\"\\nDataFrame after conversion and sorting: \")\n",
    "    print(sorted_df)\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_categorical(df,column_name,cateory_order):\n",
    "    df[column_name]=pd.Categorical(df[column_name],categories=category_order,ordered=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196179c6",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb776b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def main():\n",
    "    file_path=input(\"enter the CSV file path\")\n",
    "    visualize_data(file_path)\n",
    "\n",
    "    \n",
    "def visualize_data(file_path):\n",
    "    df=pd.read_csv(file_path)\n",
    "    \n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    pivot_df=df.pivot_table(index='Date',columns='Product category',values='Sales',aggfunc='sum')\n",
    "    pivot_df.plot(kind='bar',stacked=True,figsize=(10,6))\n",
    "    plt.xlabel('date')\n",
    "    plt.ylabel('Sales')\n",
    "    plt.title('Stacked bar chart')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1264c",
   "metadata": {},
   "source": [
    "## Question 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "903909dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_stats(file_path):\n",
    "    df=pd.read_csv(file_path)\n",
    "    mean_score=df['Test Score'].mean()\n",
    "    median_score=df['Test Score'].median()\n",
    "    mode_score=df['Test Score'].mode()\n",
    "    \n",
    "    table =tabulate([\n",
    "        ['Mean',mean_score],\n",
    "        ['Median',median_score],\n",
    "        ['Mode',', '.join(map(str,mode_score))]],\n",
    "        headers=['Statistics','Value'],\n",
    "        tablefmt='grid'\n",
    "    )\n",
    "    print(table)\n",
    "    \n",
    "def main():\n",
    "    file_path=input(\"enter the path of the CSV file\")\n",
    "    calculate_stats(file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d198bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
