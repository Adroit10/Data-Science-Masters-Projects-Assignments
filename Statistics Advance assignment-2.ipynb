{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81349533",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383eefd",
   "metadata": {},
   "source": [
    "##### Probability Mass Function (PMF) \n",
    "\n",
    "The PMF is applicable to discrete random variables, which take on a finite or countably infinite set of distinct values. It gives the probability that a discrete random variable is exactly equal to some value. Mathematically, for a discrete random variable X, the PMF is defined as P(X = x), where P represents the probability. The PMF satisfies two properties: 0 ≤ P(X = x) ≤ 1 for all x, and the sum of P(X = x) over all possible values of x is equal to 1. If X represents the outcome of rolling a fair six-sided die, the PMF would be P(X = 1), P(X = 2), ..., P(X = 6), each equal to 1/6.\n",
    "\n",
    "\n",
    "###### Probability Density Function (PDF)\n",
    "\n",
    "The PDF is used for continuous random variables, which can take any value within a specified range. Unlike the PMF, the PDF doesn't give the probability of a specific outcome but rather the probability density at a particular point. The probability of a continuous random variable falling within a particular interval is given by the area under the PDF over that interval. The PDF must satisfy two conditions: it must be non-negative for all values, and the area under the curve must be equal to 1. If X represents the height of people in a population, the PDF might describe the likelihood of observing a height within a certain range, such as the probability that a person's height is between 5 feet and 6 feet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35d2e9",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dbf16",
   "metadata": {},
   "source": [
    "The Cumulative Distribution Function (CDF) is a function associated with a probability distribution. It describes the probability that a random variable takes on a value less than or equal to a given point. For a random variable X, the CDF is denoted as F(x) and is defined as:\n",
    "F(x)=P(X≤x)\n",
    "\n",
    "\n",
    "The CDF provides cumulative information about the probability distribution. It gives a complete picture of the likelihood of observing values up to a certain point.  It simplifies the calculation of probabilities for a random variable being less than or equal to a specific value. CDFs are useful for comparing different distributions or different parameters of the same distribution. Comparing the CDFs can reveal insights into the shapes and characteristics of probability distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11cba3d",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b67e01",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution or bell curve, is widely used to model various phenomena in different fields due to its mathematical properties and its ability to describe many natural processes. The heights and weights of a population are often modeled using the normal distribution. For example, human heights and weights tend to follow approximately normal distributions. Returns on investments in financial markets are often assumed to be normally distributed. This assumption is the basis for many financial models. The normal distribution is characterized by two parameters: the mean and the standard deviation. These parameters play a crucial role in shaping the distribution. The mean is the central point of the distribution. It determines the location of the peak of the curve. Shifting the mean left or right moves the entire distribution along the x-axis. The standard deviation measures the spread or dispersion of the distribution. A larger standard deviation leads to a wider and flatter distribution, while a smaller standard deviation results in a narrower and taller distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5eded",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74031302",
   "metadata": {},
   "source": [
    "The normal distribution is important in statistics and data analysis for several reasons, and it is commonly used in a wide range of applications due to its mathematical properties. Here are some key reasons for the importance of the normal distribution : \n",
    "\n",
    "Central Limit Theorem: \n",
    "\n",
    "The normal distribution is a key component of the Central Limit Theorem, which states that the sum (or average) of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables. This theorem is fundamental in statistical inference.\n",
    "\n",
    " Risk Management in Finance:\n",
    "\n",
    "In finance, the normal distribution is frequently used to model the distribution of asset returns. This is the basis for concepts such as value-at-risk (VaR), which measures the potential loss in a financial portfolio.\n",
    "\n",
    "\n",
    "In real life there are many applications of normal distribution:\n",
    "\n",
    "1. Exam Scores: The scores on standardized tests, such as SAT or GRE, often exhibit a normal distribution among test-takers.\n",
    "\n",
    "2. Stock Prices: Daily stock price changes are often assumed to follow a normal distribution, which is a fundamental assumption in financial modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d110e5",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff360d3b",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with only two possible outcomes: \"success\" and \"failure.\" It is named after Jacob Bernoulli, a Swiss mathematician. The outcomes are often denoted as 1 for success and 0 for failure. Example : Consider a single toss of a biased coin, where \"Heads\" is considered success (1) and \"Tails\" is considered failure (0). Now, the Bernoulli distribution is a special case of the binomial distribution with a single trial. The key difference between the Bernoulli distribution and the binomial distribution lies in the number of trials.\n",
    "\n",
    "The binomial distribution models the number of successes in a fixed number of independent and identical Bernoulli trials. For example tossing of a coin n number of times is a binomial experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3438d0e",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19b12d",
   "metadata": {},
   "source": [
    "To find the probability that a randomly selected observation from a normal distribution will be greater than a certain value, you can use the z-score and the standard normal distribution table.\n",
    "\n",
    "The z-score formula is given as z= (X-mean)/std  \n",
    "\n",
    "The X in our example is 60 the mean is given as 50 and the standard deviation value is 10.\n",
    "Therefore the z score value is (60-50)/10 = 1\n",
    "Now we look in the z-score table and find out the probability value that corresponds to the z-score value of 1. Which is 0.8413. This value is the area of the curve towards the left of value X=60 therefore the correct probabilistic value is 1-0.8413 as the entire area value is 1 for a normal distribution. \n",
    "\n",
    "Therefore for a randomly selected observation to be greater than 60 is 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f35e4",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c18be5",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that describes a situation where all possible outcomes are equally likely. In other words, each value within a certain range has an equal probability of occurring. The probability density function (PDF) of a continuous uniform distribution is constant over the range of possible values and zero elsewhere. \n",
    "The probability density function for a continuous uniform distribution defined on the interval [a,b] is given by:\n",
    "\n",
    "f(x) = 1/(b-a)\n",
    "\n",
    "where a and b are the minimum and the maximum values in a range.\n",
    "\n",
    "Example::\n",
    "\n",
    "Consider a fair six-sided die. The outcomes (1, 2, 3, 4, 5, 6) are all equally likely when the die is rolled. The probability of each individual outcome is (1/6) because there are six possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d358a70c",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192235e",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score or z-value, is a statistical measure that describes a value's relationship to the mean of a group of values. It is expressed in terms of standard deviations from the mean. The formula for calculating the z-score of a data point X in a population with given mean and standard deviation is given as :\n",
    "z = (X-mean)/std\n",
    "\n",
    "Where X is individual data point, mean is the population mean , std is the population standard deviation. The resulting z-score indicates how many standard deviations an observation or data point is from the mean. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that the data point is below the mean.\n",
    "\n",
    "Importance of z-score :\n",
    "\n",
    "1. Standardization :\n",
    "\n",
    "Z-scores standardize data, allowing for comparisons between different datasets or variables. This is particularly useful when dealing with variables measured in different units or with different scales.\n",
    "\n",
    "2. Identification of Outliers:\n",
    "\n",
    "Z-scores can help identify outliers in a dataset. Observations with extreme z-scores (far from 0) may be considered unusual or noteworthy.\n",
    "\n",
    "3. Data Transformation:\n",
    "\n",
    "Z-scores are often used in statistical analyses, such as hypothesis testing and regression, where the assumption of normality is important. Transforming data into z-scores helps meet the normality assumption.\n",
    "\n",
    "4. Probability and Normal Distribution:\n",
    "\n",
    "In a standard normal distribution (a normal distribution with mean 0 and standard deviation 1), z-scores directly correspond to probabilities. The z-score is used to look up probabilities in the standard normal distribution table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350566e",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9d439",
   "metadata": {},
   "source": [
    "Central Limit Theorem states that the sum (or average) of a large number of independent and identically distributed random variables will be approximately normally distributed, regardless of the original distribution of the variables. This theorem is fundamental in statistical inference.\n",
    "\n",
    "The CLT allows researchers to assume approximate normality in the sampling distribution of the sample mean, even if the underlying population distribution is not normal. This is crucial for making statistical inferences. The CLT is the foundation for many statistical inference procedures, such as hypothesis testing and confidence intervals. It provides a basis for making probabilistic statements about population parameters based on sample statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0957a",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fa1bc5",
   "metadata": {},
   "source": [
    "The assumptions are crucial for the theorem to hold and for accurate statistical inferences. Here are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "1. Random sampling:\n",
    "The samples must be drawn randomly from the population. This means that each individual in the population has an equal chance of being selected in the sample, and the selection of one individual does not influence the selection of another.\n",
    "\n",
    "2. Sample Size: \n",
    "The Central Limit Theorem is most effective when the sample size is sufficiently large. While there is no fixed rule for what constitutes \"large,\" a commonly cited guideline is that a sample size of 30 or more is often considered adequate for the CLT to apply. However, the larger the sample size, the better the approximation to normality.\n",
    "\n",
    "3. Independence:\n",
    "The individual observations in the sample must be independent of each other. The occurrence or value of one observation should not affect the occurrence or value of another. In the case of time-ordered data, this assumes that observations are taken at random intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b92d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
